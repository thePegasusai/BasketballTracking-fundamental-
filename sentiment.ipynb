{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoQ15YZoq4x4+LfpTHWvSQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thePegasusai/BasketballTracking-fundamental-/blob/main/sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWjOiv_ytouT",
        "outputId": "1d48ada6-1a79-4d34-a829-655d7d9edd2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement ntlk (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for ntlk\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install ntlk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "with open ('conversation.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "words = word_tokenize(text)\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "scores = sia.polarity_scores(text)\n",
        "\n",
        "print('Sentiment Scores:')\n",
        "print('Positive: ', scores['pos'])\n",
        "print('Negative: ', scores['neg'])\n",
        "print('Neutral: ', scores['neu'])\n",
        "print('Compound: ', scores['compound'])\n",
        "print()\n",
        "print('Tokenized Words:')\n",
        "print(words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iDy-TYvtrev",
        "outputId": "c9b7608b-0d29-4d18-a484-1ba3ffbf847c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Scores:\n",
            "Positive:  0.1\n",
            "Negative:  0.0\n",
            "Neutral:  0.9\n",
            "Compound:  0.9524\n",
            "\n",
            "Tokenized Words:\n",
            "['Question', ':', 'Teach', 'me', 'something', 'about', 'foreign', 'issuers', 'Response', ':', 'Foreign', 'issuers', 'are', 'companies', 'that', 'are', 'based', 'in', 'a', 'country', 'other', 'than', 'the', 'United', 'States', '.', 'These', 'companies', 'may', 'be', 'required', 'to', 'meet', 'different', 'regulatory', 'requirements', 'in', 'order', 'to', 'sell', 'their', 'securities', 'in', 'the', 'US', 'markets', '.', 'For', 'example', ',', 'a', 'foreign', 'issuer', 'may', 'be', 'required', 'to', 'file', 'a', 'registration', 'statement', 'with', 'the', 'US', 'Securities', 'and', 'Exchange', 'Commission', '(', 'SEC', ')', 'in', 'order', 'to', 'sell', 'its', 'securities', 'in', 'the', 'US', '.', 'Question', ':', 'Teach', 'me', 'something', 'about', 'foreign', 'issuers', 'Response', ':', 'There', 'are', 'a', 'few', 'key', 'things', 'to', 'know', 'about', 'foreign', 'issuers', 'when', 'it', 'comes', 'to', 'startup', 'law', '.', 'First', ',', 'it', \"'s\", 'important', 'to', 'understand', 'the', 'different', 'types', 'of', 'foreign', 'issuers', '.', 'There', 'are', 'two', 'main', 'types', ':', 'public', 'and', 'private', '.', 'Public', 'foreign', 'issuers', 'are', 'companies', 'that', 'are', 'listed', 'on', 'a', 'stock', 'exchange', ',', 'while', 'private', 'foreign', 'issuers', 'are', 'companies', 'that', 'are', 'not', '.', 'Second', ',', 'it', \"'s\", 'important', 'to', 'know', 'the', 'difference', 'between', 'accredited', 'and', 'non-accredited', 'investors', '.', 'Accredited', 'investors', 'are', 'typically', 'institutional', 'investors', 'or', 'individuals', 'with', 'a', 'high', 'net', 'worth', '.', 'Non-accredited', 'investors', 'are', 'everyone', 'else', '.', 'Third', ',', 'it', \"'s\", 'important', 'to', 'be', 'familiar', 'with', 'the', 'rules', 'and', 'regulations', 'that', 'apply', 'to', 'foreign', 'issuers', '.', 'These', 'can', 'vary', 'depending', 'on', 'the', 'country', 'in', 'which', 'the', 'company', 'is', 'based', '.', 'Finally', ',', 'it', \"'s\", 'important', 'to', 'seek', 'out', 'experienced', 'legal', 'counsel', 'when', 'dealing', 'with', 'foreign', 'issuers', '.', 'This', 'is', 'because', 'the', 'laws', 'and', 'regulations', 'can', 'be', 'complex', ',', 'and', 'it', \"'s\", 'important', 'to', 'make', 'sure', 'that', 'all', 'of', 'the', 'proper', 'paperwork', 'is', 'filed', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import sqlite3\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Define the database schema\n",
        "schema = '''\n",
        "CREATE TABLE IF NOT EXISTS files (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    file_name TEXT NOT NULL,\n",
        "    text_content TEXT NOT NULL,\n",
        "    tokenized_words TEXT NOT NULL\n",
        ");\n",
        "'''\n",
        "\n",
        "# Create a new database\n",
        "conn = sqlite3.connect('tokenized_db.sqlite')\n",
        "c = conn.cursor()\n",
        "\n",
        "# Create the table\n",
        "c.execute(schema)\n",
        "conn.commit()\n",
        "\n",
        "# Read the file\n",
        "with open ('conversation.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Tokenize the words\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Analyze the sentiment\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "scores = sia.polarity_scores(text)\n",
        "\n",
        "# Save the data into the database\n",
        "data = (None, 'conversation.txt', text, ' '.join(words))\n",
        "c.execute('INSERT INTO files VALUES (?, ?, ?, ?)', data)\n",
        "conn.commit()\n",
        "\n",
        "# Print the results\n",
        "print('Sentiment Scores:')\n",
        "print('Positive: ', scores['pos'])\n",
        "print('Negative: ', scores['neg'])\n",
        "print('Neutral: ', scores['neu'])\n",
        "print('Compound: ', scores['compound'])\n",
        "print()\n",
        "print('Tokenized Words:')\n",
        "print(words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G10wbLuQveYN",
        "outputId": "aef75f27-e4ba-403d-fff4-5f824feea05c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Scores:\n",
            "Positive:  0.1\n",
            "Negative:  0.0\n",
            "Neutral:  0.9\n",
            "Compound:  0.9524\n",
            "\n",
            "Tokenized Words:\n",
            "['Question', ':', 'Teach', 'me', 'something', 'about', 'foreign', 'issuers', 'Response', ':', 'Foreign', 'issuers', 'are', 'companies', 'that', 'are', 'based', 'in', 'a', 'country', 'other', 'than', 'the', 'United', 'States', '.', 'These', 'companies', 'may', 'be', 'required', 'to', 'meet', 'different', 'regulatory', 'requirements', 'in', 'order', 'to', 'sell', 'their', 'securities', 'in', 'the', 'US', 'markets', '.', 'For', 'example', ',', 'a', 'foreign', 'issuer', 'may', 'be', 'required', 'to', 'file', 'a', 'registration', 'statement', 'with', 'the', 'US', 'Securities', 'and', 'Exchange', 'Commission', '(', 'SEC', ')', 'in', 'order', 'to', 'sell', 'its', 'securities', 'in', 'the', 'US', '.', 'Question', ':', 'Teach', 'me', 'something', 'about', 'foreign', 'issuers', 'Response', ':', 'There', 'are', 'a', 'few', 'key', 'things', 'to', 'know', 'about', 'foreign', 'issuers', 'when', 'it', 'comes', 'to', 'startup', 'law', '.', 'First', ',', 'it', \"'s\", 'important', 'to', 'understand', 'the', 'different', 'types', 'of', 'foreign', 'issuers', '.', 'There', 'are', 'two', 'main', 'types', ':', 'public', 'and', 'private', '.', 'Public', 'foreign', 'issuers', 'are', 'companies', 'that', 'are', 'listed', 'on', 'a', 'stock', 'exchange', ',', 'while', 'private', 'foreign', 'issuers', 'are', 'companies', 'that', 'are', 'not', '.', 'Second', ',', 'it', \"'s\", 'important', 'to', 'know', 'the', 'difference', 'between', 'accredited', 'and', 'non-accredited', 'investors', '.', 'Accredited', 'investors', 'are', 'typically', 'institutional', 'investors', 'or', 'individuals', 'with', 'a', 'high', 'net', 'worth', '.', 'Non-accredited', 'investors', 'are', 'everyone', 'else', '.', 'Third', ',', 'it', \"'s\", 'important', 'to', 'be', 'familiar', 'with', 'the', 'rules', 'and', 'regulations', 'that', 'apply', 'to', 'foreign', 'issuers', '.', 'These', 'can', 'vary', 'depending', 'on', 'the', 'country', 'in', 'which', 'the', 'company', 'is', 'based', '.', 'Finally', ',', 'it', \"'s\", 'important', 'to', 'seek', 'out', 'experienced', 'legal', 'counsel', 'when', 'dealing', 'with', 'foreign', 'issuers', '.', 'This', 'is', 'because', 'the', 'laws', 'and', 'regulations', 'can', 'be', 'complex', ',', 'and', 'it', \"'s\", 'important', 'to', 'make', 'sure', 'that', 'all', 'of', 'the', 'proper', 'paperwork', 'is', 'filed', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MY5GEJ1Cv-oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LAwF5zBMv_DE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}